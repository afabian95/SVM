{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fabian Ardeljan\n",
    "# Data Mining\n",
    "# Dr. Ye\n",
    "\n",
    "import numpy as np\n",
    "from libsvm.svmutil import *\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = svm_read_problem('./DogsVsCats/DogsVsCats.train')\n",
    "y_testset, X_testset = svm_read_problem('./DogsVsCats/DogsVsCats.test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) SVM Accuracy and Cross-Validation for Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1:   TRAIN: [    0     1     3 ... 12497 12498 12499] TEST: [    2    28    29 ... 12476 12490 12491]\n",
      "Training linear model\n",
      "Testing linear model\n",
      "Accuracy = 60.0356% (6754/11250) (classification)\n",
      "Training polynomial model\n",
      "Testing polynomial model\n",
      "Accuracy = 50.1333% (5640/11250) (classification)\n",
      "\n",
      "FOLD 2:   TRAIN: [    0     1     2 ... 12497 12498 12499] TEST: [   10    15    26 ... 12462 12486 12489]\n",
      "Training linear model\n",
      "Testing linear model\n",
      "Accuracy = 60.2667% (6780/11250) (classification)\n",
      "Training polynomial model\n",
      "Testing polynomial model\n",
      "Accuracy = 50.1244% (5639/11250) (classification)\n",
      "\n",
      "FOLD 3:   TRAIN: [    0     1     2 ... 12497 12498 12499] TEST: [   16    20    23 ... 12482 12492 12494]\n",
      "Training linear model\n",
      "Testing linear model\n",
      "Accuracy = 59.8756% (6736/11250) (classification)\n",
      "Training polynomial model\n",
      "Testing polynomial model\n",
      "Accuracy = 50.0356% (5629/11250) (classification)\n",
      "\n",
      "FOLD 4:   TRAIN: [    0     2     3 ... 12497 12498 12499] TEST: [    1    22    45 ... 12444 12453 12454]\n",
      "Training linear model\n",
      "Testing linear model\n",
      "Accuracy = 60.08% (6759/11250) (classification)\n",
      "Training polynomial model\n",
      "Testing polynomial model\n",
      "Accuracy = 50.0178% (5627/11250) (classification)\n",
      "\n",
      "FOLD 5:   TRAIN: [    0     1     2 ... 12496 12498 12499] TEST: [   13    33    38 ... 12487 12488 12497]\n",
      "Training linear model\n",
      "Testing linear model\n",
      "Accuracy = 60.0622% (6757/11250) (classification)\n",
      "Training polynomial model\n",
      "Testing polynomial model\n",
      "Accuracy = 50.0533% (5631/11250) (classification)\n",
      "\n",
      "FOLD 6:   TRAIN: [    0     1     2 ... 12497 12498 12499] TEST: [    6     8    11 ... 12469 12471 12496]\n",
      "Training linear model\n",
      "Testing linear model\n",
      "Accuracy = 60.0622% (6757/11250) (classification)\n",
      "Training polynomial model\n",
      "Testing polynomial model\n",
      "Accuracy = 50.08% (5634/11250) (classification)\n",
      "\n",
      "FOLD 7:   TRAIN: [    0     1     2 ... 12494 12496 12497] TEST: [    9    17    35 ... 12495 12498 12499]\n",
      "Training linear model\n",
      "Testing linear model\n",
      "Accuracy = 60.08% (6759/11250) (classification)\n",
      "Training polynomial model\n",
      "Testing polynomial model\n",
      "Accuracy = 50.0178% (5627/11250) (classification)\n",
      "\n",
      "FOLD 8:   TRAIN: [    0     1     2 ... 12497 12498 12499] TEST: [    3     4    21 ... 12442 12485 12493]\n",
      "Training linear model\n",
      "Testing linear model\n",
      "Accuracy = 60.0889% (6760/11250) (classification)\n",
      "Training polynomial model\n",
      "Testing polynomial model\n",
      "Accuracy = 50.1333% (5640/11250) (classification)\n",
      "\n",
      "FOLD 9:   TRAIN: [    1     2     3 ... 12497 12498 12499] TEST: [    0     7    12 ... 12451 12457 12468]\n",
      "Training linear model\n",
      "Testing linear model\n",
      "Accuracy = 59.9822% (6748/11250) (classification)\n",
      "Training polynomial model\n",
      "Testing polynomial model\n",
      "Accuracy = 50.0533% (5631/11250) (classification)\n",
      "\n",
      "FOLD 10:   TRAIN: [    0     1     2 ... 12497 12498 12499] TEST: [    5    31    39 ... 12472 12481 12484]\n",
      "Training linear model\n",
      "Testing linear model\n",
      "Accuracy = 60.1689% (6769/11250) (classification)\n",
      "Training polynomial model\n",
      "Testing polynomial model\n",
      "Accuracy = 50.1689% (5644/11250) (classification)\n",
      "\n",
      "Linear kernel average validation accuracy: 60.07%\n",
      "Polynomial kernel average validation accuracy: 50.08%\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10, random_state=12345, shuffle=True)\n",
    "fold_num = 0\n",
    "linear_val_acc = []\n",
    "polynomial_val_acc = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    fold_num += 1\n",
    "    print(\"FOLD \" + str(fold_num) + \":   TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    y_train = np.array(y)[train_index]\n",
    "    X_train = np.array(X)[train_index]\n",
    "    y_test = np.array(y)[train_index]\n",
    "    X_test = np.array(X)[train_index]\n",
    "    \n",
    "    print(\"Training linear model\")\n",
    "    linear_model = svm_train(y_train, X_train, '-t 0')\n",
    "    print(\"Testing linear model\")\n",
    "    p_label, p_acc, p_val = svm_predict(y_test, X_test, linear_model)\n",
    "    linear_val_acc.append(p_acc[0])\n",
    "    \n",
    "    print(\"Training polynomial model\")\n",
    "    polynomial_model = svm_train(y_train, X_train, '-t 1 -d 5')\n",
    "    print(\"Testing polynomial model\")\n",
    "    p_label, p_acc, p_val = svm_predict(y_test, X_test, polynomial_model)\n",
    "    polynomial_val_acc.append(p_acc[0])\n",
    "    print()\n",
    "    \n",
    "lin_val_acc = np.mean(linear_val_acc)\n",
    "pol_val_acc = np.mean(polynomial_val_acc)\n",
    "print(\"Linear kernel average validation accuracy: \" + \"{:.2f}\".format(lin_val_acc) + \"%\")\n",
    "print(\"Polynomial kernel average validation accuracy: \" + \"{:.2f}\".format(pol_val_acc) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training linear model\n",
      "Testing linear model on training data\n",
      "Accuracy = 60.12% (7515/12500) (classification)\n",
      "Testing linear model on test data\n",
      "Accuracy = 59.2% (7400/12500) (classification)\n",
      "\n",
      "Training polynomial model\n",
      "Testing polynomial model on training data\n",
      "Accuracy = 50.024% (6253/12500) (classification)\n",
      "Testing polynomial model on test data\n",
      "Accuracy = 50.048% (6256/12500) (classification)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training linear model\")\n",
    "linear_model = svm_train(y, X, '-t 0')\n",
    "print(\"Testing linear model on training data\")\n",
    "p_label, p_acc, p_val = svm_predict(y, X, linear_model)\n",
    "lin_trn_acc = p_acc[0]\n",
    "print(\"Testing linear model on test data\")\n",
    "p_label, p_acc, p_val = svm_predict(y_testset, X_testset, linear_model)\n",
    "lin_tst_acc = p_acc[0]\n",
    "print()\n",
    "\n",
    "print(\"Training polynomial model\")\n",
    "polynomial_model = svm_train(y, X, '-t 1 -d 5')\n",
    "print(\"Testing polynomial model on training data\")\n",
    "p_label, p_acc, p_val = svm_predict(y, X, polynomial_model)\n",
    "pol_trn_acc = p_acc[0]\n",
    "print(\"Testing polynomial model on test data\")\n",
    "p_label, p_acc, p_val = svm_predict(y_testset, X_testset, polynomial_model)\n",
    "pol_tst_acc = p_acc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "\n",
      "Linear Kernel:\n",
      "Training accuracy: 60.12%\n",
      "Validation accuracy: 60.07%\n",
      "Testing accuracy: 59.20%\n",
      "\n",
      "Polynomial Kernel:\n",
      "Training accuracy: 50.02%\n",
      "Validation accuracy: 50.08%\n",
      "Testing accuracy: 50.05%\n"
     ]
    }
   ],
   "source": [
    "print(\"Results\")\n",
    "print()\n",
    "print(\"Linear Kernel:\")\n",
    "print(\"Training accuracy: \" + \"{:.2f}\".format(lin_trn_acc) + \"%\")\n",
    "print(\"Validation accuracy: \" + \"{:.2f}\".format(lin_val_acc) + \"%\")\n",
    "print(\"Testing accuracy: \" + \"{:.2f}\".format(lin_tst_acc) + \"%\")\n",
    "print()\n",
    "print(\"Polynomial Kernel:\")\n",
    "print(\"Training accuracy: \" + \"{:.2f}\".format(pol_trn_acc) + \"%\")\n",
    "print(\"Validation accuracy: \" + \"{:.2f}\".format(pol_val_acc) + \"%\")\n",
    "print(\"Testing accuracy: \" + \"{:.2f}\".format(pol_tst_acc) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation accuracy gives a very similar prediction of the test accuracy as the training accuracy. The linear kernel has higher test accuracy than the polynomial kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Boosting SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost(K):\n",
    "    weights = np.ones(len(X))\n",
    "    weights[:] = 1/len(X)\n",
    "    alphas = []\n",
    "    models = []\n",
    "    \n",
    "    for i in range(K):\n",
    "        print(\"Iteration \" + str(i + 1) + \":\")\n",
    "        \n",
    "        params = '-t 0'\n",
    "        print(\"Weights: \" + str(weights))\n",
    "        for w in range(len(weights)):\n",
    "            params += ' -w' + str(w) + ' ' + str(weights[w] * len(weights))\n",
    "        \n",
    "        print(\"Training model \" + str(i + 1))\n",
    "        linear_model = svm_train(y, X, params)\n",
    "        models.append(linear_model)\n",
    "        print(\"Testing model \" + str(i + 1) + \" on training data\")\n",
    "        p_label, p_acc, p_val = svm_predict(y, X, linear_model)\n",
    "        \n",
    "        E = 0\n",
    "        for p in range(len(p_label)):\n",
    "            if (p_label[p] != y[p]):\n",
    "                E += weights[p]\n",
    "        print(\"Error: \" + str(E))\n",
    "        alpha = 0.5 * np.log((1-E)/E)\n",
    "        alphas.append(alpha)\n",
    "        print(\"Alpha: \" + str(alpha))\n",
    "    \n",
    "        new_weights = []\n",
    "        for w in range(len(weights)):\n",
    "            new_weights.append(weights[w] * np.exp(np.array(-(alpha * y[w] * p_label[w]), dtype=np.float32)))\n",
    "        weights = new_weights/sum(new_weights)\n",
    "        print()\n",
    "        \n",
    "    predictions = []\n",
    "    for m in range(len(models)):\n",
    "        print(\"Testing model \" + str(m + 1) + \" on test data\")\n",
    "        p_label, p_acc, p_val = svm_predict(y_testset, X_testset, models[m])\n",
    "        predictions.append(p_label)\n",
    "    print()\n",
    "        \n",
    "    correct = 0\n",
    "    for x in range(len(X_testset)):\n",
    "        h = 0\n",
    "        for a in range(len(alphas)):\n",
    "            h += alphas[a] * predictions[a][x]\n",
    "        if (h > 0 and y[x] > 0) or (h <= 0 and y[x] < 0):\n",
    "            correct += 1\n",
    "            \n",
    "    h_accuracy = correct/len(X_testset)\n",
    "\n",
    "    print(\"Ensemble classifier accuracy: \" + \"{:.2f}\".format(100 * h_accuracy) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "Weights: [8.e-05 8.e-05 8.e-05 ... 8.e-05 8.e-05 8.e-05]\n",
      "Training model 1\n",
      "Testing model 1 on training data\n",
      "Accuracy = 60.12% (7515/12500) (classification)\n",
      "Error: 0.39880000000003674\n",
      "Alpha: 0.20523380989549153\n",
      "\n",
      "Iteration 2:\n",
      "Weights: [6.65336015e-05 1.00300900e-04 6.65336015e-05 ... 1.00300900e-04\n",
      " 6.65336015e-05 6.65336015e-05]\n",
      "Training model 2\n",
      "Testing model 2 on training data\n",
      "Accuracy = 57.472% (7184/12500) (classification)\n",
      "Error: 0.44564097840580097\n",
      "Alpha: 0.1091494417873163\n",
      "\n",
      "Iteration 3:\n",
      "Weights: [6.00094876e-05 1.12535544e-04 7.46493305e-05 ... 9.04656512e-05\n",
      " 6.00094876e-05 6.00094876e-05]\n",
      "Training model 3\n",
      "Testing model 3 on training data\n",
      "Accuracy = 50.424% (6303/12500) (classification)\n",
      "Error: 0.4964012998408128\n",
      "Alpha: 0.0071975246035184655\n",
      "\n",
      "Iteration 4:\n",
      "Weights: [6.04445312e-05 1.13351379e-04 7.51905069e-05 ... 8.98191864e-05\n",
      " 5.95806616e-05 5.95806616e-05]\n",
      "Training model 4\n",
      "Testing model 4 on training data\n",
      "Accuracy = 50.336% (6292/12500) (classification)\n",
      "Error: 0.5002789932372051\n",
      "Alpha: -0.0005579865323197853\n",
      "\n",
      "Iteration 5:\n",
      "Weights: [6.04108226e-05 1.13288165e-04 7.51485748e-05 ... 8.98693325e-05\n",
      " 5.96139255e-05 5.96139255e-05]\n",
      "Training model 5\n",
      "Testing model 5 on training data\n",
      "Accuracy = 50.36% (6295/12500) (classification)\n",
      "Error: 0.4998213565334419\n",
      "Alpha: 0.00035728694831918447\n",
      "\n",
      "Iteration 6:\n",
      "Weights: [6.04324151e-05 1.13328658e-04 7.51754350e-05 ... 8.98372336e-05\n",
      " 5.95926330e-05 5.95926330e-05]\n",
      "Training model 6\n",
      "Testing model 6 on training data\n",
      "Accuracy = 50.344% (6293/12500) (classification)\n",
      "Error: 0.5001190588711323\n",
      "Alpha: -0.0002381177467649889\n",
      "\n",
      "Iteration 7:\n",
      "Weights: [6.04180283e-05 1.13301678e-04 7.51575384e-05 ... 8.98586308e-05\n",
      " 5.96068266e-05 5.96068266e-05]\n",
      "Training model 7\n",
      "Testing model 7 on training data\n",
      "Accuracy = 50.352% (6294/12500) (classification)\n",
      "Error: 0.49994048660518553\n",
      "Alpha: 0.00011902679019103651\n",
      "\n",
      "Iteration 8:\n",
      "Weights: [6.04252226e-05 1.13315170e-04 7.51664878e-05 ... 8.98479335e-05\n",
      " 5.95997307e-05 5.95997307e-05]\n",
      "Training model 8\n",
      "Testing model 8 on training data\n",
      "Accuracy = 50.344% (6293/12500) (classification)\n",
      "Error: 0.5000595216529554\n",
      "Alpha: -0.00011904330647318952\n",
      "\n",
      "Iteration 9:\n",
      "Weights: [6.04180292e-05 1.13301680e-04 7.51575395e-05 ... 8.98586321e-05\n",
      " 5.96068275e-05 5.96068275e-05]\n",
      "Training model 9\n",
      "Testing model 9 on training data\n",
      "Accuracy = 50.352% (6294/12500) (classification)\n",
      "Error: 0.49994049368908927\n",
      "Alpha: 0.00011901262238337221\n",
      "\n",
      "Iteration 10:\n",
      "Weights: [6.04252198e-05 1.13315165e-04 7.51664844e-05 ... 8.98479401e-05\n",
      " 5.95997351e-05 5.95997351e-05]\n",
      "Training model 10\n",
      "Testing model 10 on training data\n",
      "Accuracy = 50.344% (6293/12500) (classification)\n",
      "Error: 0.5000594847746365\n",
      "Alpha: -0.00011896954983419076\n",
      "\n",
      "Testing model 1 on test data\n",
      "Accuracy = 59.2% (7400/12500) (classification)\n",
      "Testing model 2 on test data\n",
      "Accuracy = 56.744% (7093/12500) (classification)\n",
      "Testing model 3 on test data\n",
      "Accuracy = 50.104% (6263/12500) (classification)\n",
      "Testing model 4 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 5 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 6 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 7 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 8 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 9 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 10 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "\n",
      "Ensemble classifier accuracy: 59.20%\n"
     ]
    }
   ],
   "source": [
    "AdaBoost(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 10 iterations, the test accuracy of the ensemble classifier is exactly as high as that of its best performing model, namely the unboosted model. This indicates that boosting in this case has failed. This is evident by the fact that the accuracy keeps dropping from each iteration and tends to stabilize around 50%. As a result, only the first model has relatively strong accuracy and the remaining models only pose a neglegible effect, or cancel each other out. One possible cause for this is the linear kernel not being complex enough to fit the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Increasing the number of boosting iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "Weights: [8.e-05 8.e-05 8.e-05 ... 8.e-05 8.e-05 8.e-05]\n",
      "Training model 1\n",
      "Testing model 1 on training data\n",
      "Accuracy = 60.12% (7515/12500) (classification)\n",
      "Error: 0.39880000000003674\n",
      "Alpha: 0.20523380989549153\n",
      "\n",
      "Iteration 2:\n",
      "Weights: [6.65336015e-05 1.00300900e-04 6.65336015e-05 ... 1.00300900e-04\n",
      " 6.65336015e-05 6.65336015e-05]\n",
      "Training model 2\n",
      "Testing model 2 on training data\n",
      "Accuracy = 57.472% (7184/12500) (classification)\n",
      "Error: 0.44564097840580097\n",
      "Alpha: 0.1091494417873163\n",
      "\n",
      "Iteration 3:\n",
      "Weights: [6.00094876e-05 1.12535544e-04 7.46493305e-05 ... 9.04656512e-05\n",
      " 6.00094876e-05 6.00094876e-05]\n",
      "Training model 3\n",
      "Testing model 3 on training data\n",
      "Accuracy = 50.424% (6303/12500) (classification)\n",
      "Error: 0.4964012998408128\n",
      "Alpha: 0.0071975246035184655\n",
      "\n",
      "Iteration 4:\n",
      "Weights: [6.04445312e-05 1.13351379e-04 7.51905069e-05 ... 8.98191864e-05\n",
      " 5.95806616e-05 5.95806616e-05]\n",
      "Training model 4\n",
      "Testing model 4 on training data\n",
      "Accuracy = 50.336% (6292/12500) (classification)\n",
      "Error: 0.5002789932372051\n",
      "Alpha: -0.0005579865323197853\n",
      "\n",
      "Iteration 5:\n",
      "Weights: [6.04108226e-05 1.13288165e-04 7.51485748e-05 ... 8.98693325e-05\n",
      " 5.96139255e-05 5.96139255e-05]\n",
      "Training model 5\n",
      "Testing model 5 on training data\n",
      "Accuracy = 50.36% (6295/12500) (classification)\n",
      "Error: 0.4998213565334419\n",
      "Alpha: 0.00035728694831918447\n",
      "\n",
      "Iteration 6:\n",
      "Weights: [6.04324151e-05 1.13328658e-04 7.51754350e-05 ... 8.98372336e-05\n",
      " 5.95926330e-05 5.95926330e-05]\n",
      "Training model 6\n",
      "Testing model 6 on training data\n",
      "Accuracy = 50.344% (6293/12500) (classification)\n",
      "Error: 0.5001190588711323\n",
      "Alpha: -0.0002381177467649889\n",
      "\n",
      "Iteration 7:\n",
      "Weights: [6.04180283e-05 1.13301678e-04 7.51575384e-05 ... 8.98586308e-05\n",
      " 5.96068266e-05 5.96068266e-05]\n",
      "Training model 7\n",
      "Testing model 7 on training data\n",
      "Accuracy = 50.352% (6294/12500) (classification)\n",
      "Error: 0.49994048660518553\n",
      "Alpha: 0.00011902679019103651\n",
      "\n",
      "Iteration 8:\n",
      "Weights: [6.04252226e-05 1.13315170e-04 7.51664878e-05 ... 8.98479335e-05\n",
      " 5.95997307e-05 5.95997307e-05]\n",
      "Training model 8\n",
      "Testing model 8 on training data\n",
      "Accuracy = 50.344% (6293/12500) (classification)\n",
      "Error: 0.5000595216529554\n",
      "Alpha: -0.00011904330647318952\n",
      "\n",
      "Iteration 9:\n",
      "Weights: [6.04180292e-05 1.13301680e-04 7.51575395e-05 ... 8.98586321e-05\n",
      " 5.96068275e-05 5.96068275e-05]\n",
      "Training model 9\n",
      "Testing model 9 on training data\n",
      "Accuracy = 50.352% (6294/12500) (classification)\n",
      "Error: 0.49994049368908927\n",
      "Alpha: 0.00011901262238337221\n",
      "\n",
      "Iteration 10:\n",
      "Weights: [6.04252198e-05 1.13315165e-04 7.51664844e-05 ... 8.98479401e-05\n",
      " 5.95997351e-05 5.95997351e-05]\n",
      "Training model 10\n",
      "Testing model 10 on training data\n",
      "Accuracy = 50.344% (6293/12500) (classification)\n",
      "Error: 0.5000594847746365\n",
      "Alpha: -0.00011896954983419076\n",
      "\n",
      "Iteration 11:\n",
      "Weights: [6.04180319e-05 1.13301685e-04 7.51575428e-05 ... 8.98586307e-05\n",
      " 5.96068266e-05 5.96068266e-05]\n",
      "Training model 11\n",
      "Testing model 11 on training data\n",
      "Accuracy = 50.344% (6293/12500) (classification)\n",
      "Error: 0.49999999933915323\n",
      "Alpha: 1.3216935306498767e-09\n",
      "\n",
      "Iteration 12:\n",
      "Weights: [6.04180319e-05 1.13301685e-04 7.51575428e-05 ... 8.98586307e-05\n",
      " 5.96068266e-05 5.96068266e-05]\n",
      "Training model 12\n",
      "Testing model 12 on training data\n",
      "Accuracy = 50.344% (6293/12500) (classification)\n",
      "Error: 0.4999999993391655\n",
      "Alpha: 1.3216689947210973e-09\n",
      "\n",
      "Iteration 13:\n",
      "Weights: [6.04180319e-05 1.13301685e-04 7.51575428e-05 ... 8.98586307e-05\n",
      " 5.96068266e-05 5.96068266e-05]\n",
      "Training model 13\n",
      "Testing model 13 on training data\n",
      "Accuracy = 50.344% (6293/12500) (classification)\n",
      "Error: 0.49999999933911965\n",
      "Alpha: 1.321760699142689e-09\n",
      "\n",
      "Iteration 14:\n",
      "Weights: [6.04180319e-05 1.13301685e-04 7.51575428e-05 ... 8.98586307e-05\n",
      " 5.96068266e-05 5.96068266e-05]\n",
      "Training model 14\n",
      "Testing model 14 on training data\n",
      "Accuracy = 50.344% (6293/12500) (classification)\n",
      "Error: 0.49999999933914574\n",
      "Alpha: 1.3217085186606695e-09\n",
      "\n",
      "Iteration 15:\n",
      "Weights: [6.04180319e-05 1.13301685e-04 7.51575428e-05 ... 8.98586307e-05\n",
      " 5.96068266e-05 5.96068266e-05]\n",
      "Training model 15\n",
      "Testing model 15 on training data\n",
      "Accuracy = 50.344% (6293/12500) (classification)\n",
      "Error: 0.49999999933915507\n",
      "Alpha: 1.3216898669139052e-09\n",
      "\n",
      "Iteration 16:\n",
      "Weights: [6.04180319e-05 1.13301685e-04 7.51575428e-05 ... 8.98586307e-05\n",
      " 5.96068266e-05 5.96068266e-05]\n",
      "Training model 16\n",
      "Testing model 16 on training data\n",
      "Accuracy = 50.344% (6293/12500) (classification)\n",
      "Error: 0.4999999993391136\n",
      "Alpha: 1.3217729115959275e-09\n",
      "\n",
      "Iteration 17:\n",
      "Weights: [6.04180319e-05 1.13301685e-04 7.51575428e-05 ... 8.98586307e-05\n",
      " 5.96068266e-05 5.96068266e-05]\n",
      "Training model 17\n",
      "Testing model 17 on training data\n",
      "Accuracy = 50.344% (6293/12500) (classification)\n",
      "Error: 0.4999999993391398\n",
      "Alpha: 1.3217205090693038e-09\n",
      "\n",
      "Iteration 18:\n",
      "Weights: [6.04180319e-05 1.13301685e-04 7.51575428e-05 ... 8.98586307e-05\n",
      " 5.96068266e-05 5.96068266e-05]\n",
      "Training model 18\n",
      "Testing model 18 on training data\n",
      "Accuracy = 50.344% (6293/12500) (classification)\n",
      "Error: 0.4999999993391521\n",
      "Alpha: 1.32169575109592e-09\n",
      "\n",
      "Iteration 19:\n",
      "Weights: [6.04180319e-05 1.13301685e-04 7.51575428e-05 ... 8.98586307e-05\n",
      " 5.96068266e-05 5.96068266e-05]\n",
      "Training model 19\n",
      "Testing model 19 on training data\n",
      "Accuracy = 50.344% (6293/12500) (classification)\n",
      "Error: 0.49999999933916545\n",
      "Alpha: 1.3216691057433995e-09\n",
      "\n",
      "Iteration 20:\n",
      "Weights: [6.04180319e-05 1.13301685e-04 7.51575428e-05 ... 8.98586307e-05\n",
      " 5.96068266e-05 5.96068266e-05]\n",
      "Training model 20\n",
      "Testing model 20 on training data\n",
      "Accuracy = 50.344% (6293/12500) (classification)\n",
      "Error: 0.49999999933911937\n",
      "Alpha: 1.321761365276502e-09\n",
      "\n",
      "Testing model 1 on test data\n",
      "Accuracy = 59.2% (7400/12500) (classification)\n",
      "Testing model 2 on test data\n",
      "Accuracy = 56.744% (7093/12500) (classification)\n",
      "Testing model 3 on test data\n",
      "Accuracy = 50.104% (6263/12500) (classification)\n",
      "Testing model 4 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 5 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 6 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 7 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 8 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 9 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 10 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 11 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 12 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 13 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 14 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 15 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 16 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 17 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 18 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 19 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "Testing model 20 on test data\n",
      "Accuracy = 50.096% (6262/12500) (classification)\n",
      "\n",
      "Ensemble classifier accuracy: 59.20%\n"
     ]
    }
   ],
   "source": [
    "AdaBoost(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 20 iterations, the test accuracy of the ensemble classifier remains only as high as the best performing model. This was to be expected as the alpha value dropped steeply after the first three iterations, meaning future alpha values remained negligible. In order for AdaBoost to work, the first few iterations must remain high in accuracy in order to have an effect on the overall result. For this particular dataset using a linear kernel, the maximum accuracy seems to be saturated in the unboosted SVM. If the original boosting attempt failed due to the linear kernel underfitting the data, adding more iterations is unlikely to fix the problem. A different kernel should be chosen instead."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
